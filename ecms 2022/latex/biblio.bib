%%%%%%%%%%%%%%%%%%%%%%%%%%%% 1 INTRO %%%%%%%%%%%%%%%%%%%%%%%%%%%%  

@article{Hornik,
title = {Multilayer feedforward networks are universal approximators},
journal = {Neural Networks},
volume = {2},
number = {5},
pages = {359-366},
year = {1989},
issn = {0893-6080},
doi = {https://doi.org/10.1016/0893-6080(89)90020-8},
url = {https://www.sciencedirect.com/science/article/pii/0893608089900208},
author = {Kurt Hornik and Maxwell Stinchcombe and Halbert White},
keywords = {Feedforward networks, Universal approximation, Mapping networks, Network representation capability, Stone-Weierstrass Theorem, Squashing functions, Sigma-Pi networks, Back-propagation networks},
abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.}
}

@article{ZhouCNN,
author = {Zhou, Ding-Xuan},
year = {2019},
month = {06},
pages = {},
title = {Universality of deep convolutional neural networks},
volume = {48},
journal = {Applied and Computational Harmonic Analysis},
doi = {10.1016/j.acha.2019.06.004}
}

@article{ConvNetOCR,
  author = {Andreeva, E. I. and Arlazarov, V. V. and Gayer, A. V. and Dorokhov, E. P. and Sheshkus, A. V. and Slavin, O. A.},
  title = {Document Recognition Method Based on Convolutional Neural Network Invariant to 180 Degree Rotation Angle},
  year = 2019,
  journal = {ITiVS},
  editor = {Popkov Yuriy Solomonovich},
  publisher = {Federalnoe gosudarstvennoe uchrezhdenie Federalnyy issledovatelskiy tsentr «Informatika i upravlenie» Rossiyskoy akademii nauk (FITs IU RAN)},
  address = {Adres: 119333, g. Moskva, ul. Vavilova, d.44, kor.2},
  organization = {FRC CSC RAS},
  number = {4},
  pages = {87--93},
  note={DOI: 10.14357/20718632190408}
}


@article{ResNetDetection,
  author = {Lobanov, M. G. and Sholomov, D. L.},
  title = {On the Acceleration of the Convolutional Neural Network Architecture Based on Resnet in the Task of Road Scene Objects Recognition},
  year = 2019,
  journal = {ITiVS},
  editor = {Popkov Yuriy Solomonovich},
  publisher = {Federalnoe gosudarstvennoe uchrezhdenie Federalnyy issledovatelskiy tsentr «Informatika i upravlenie» Rossiyskoy akademii nauk (FITs IU RAN)},
  address = {Adres: 119333, g. Moskva, ul. Vavilova, d.44, kor.2},
  organization = {FRC CSC RAS},
  volume = 69,
  number = {3},
  pages = {57--65},
  note={DOI: 10.14357/20718632190305}
}


@article{CannyOptics,
  author = {Karnaushkin, P. V. and Sklyarenko, M. S.},
  title = {Computer vision-based method of pre-alignment of a channel optical waveguide and a lensed fiber.},
  year = 2022,
  journal = {Computer Optics},
  volume = 46,
  number = {1},
  pages = {71--82},
  note={DOI: 10.18287/2412-6179-CO-919}
}



%%%%%%%%%%% 1.1 NEURAL APPROXIMATION OF CLASSICAL ALGORITHMS %%%%%%%%%%% 

@article{Fernandez11,
author = {Fernández, Andrea and Delgado-Mata, Carlos and Velázquez, Ramiro},
year = {2011},
month = {11},
pages = {},
title = {Training a Single-Layer Perceptron for an Approximate Edge Detection on a Digital Image},
journal = {Proceedings - 2011 Conference on Technologies and Applications of Artificial Intelligence, TAAI 2011},
doi = {10.1109/TAAI.2011.40}
}


@article{Ridder99Kuwahara,
author = {De Ridder, D. and Duin, R. P. W. and Verbeek, P. W. and Van Vliet, L. J.},
title = {The Applicability of Neural Networks to Non-Linear Image Processing},
year = {1999},
issue_date = {June 1999},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {2},
number = {2},
issn = {1433-7541},
url = {https://doi.org/10.1007/s100440050022},
doi = {10.1007/s100440050022},
abstract = {In this paper, the applicability of neural networks to non-linear image processing
problems is studied. As an example, the Kuwahara filtering for edge-preserving smoothing
was chosen. This filter is interesting due to its non-linear nature and natural modularity.
A number of modular networks were constructed and trained, incorporating prior knowledge
in various degrees and their performance was compared to standard feed-forward neural
networks (MLPs). Based on results obtained in these experiments, it is shown that
several key factors influence neural network behaviour in this kind of task. First,
it is demonstrated that the mean squared error criterion used in neural network training
is not representative for the problem. To be able to discern performance differences
better, a new error measure for edge-preserving smoothing operations is proposed.
Secondly, using this measure, it is shown that modular networks perform better than
standard feed-forward networks. The latter type often ends up in linear approximations
to the filter. Finally, inspection of the modular networks shows that, although analysis
is difficult due to their non-linearity, one can draw some conclusions regarding the
effect of design and training choices. The main conclusion is that neural networks
can be applied to non-linear image processing problems, provided that careful attention
is paid to network architecture, training set sampling and parameter choice. Only
if prior knowledge is used in constructing the networks and sampling the datasets
can one expect to obtain a well performing neural network filter.},
journal = {Pattern Anal. Appl.},
month = jun,
pages = {111–128},
numpages = {18},
keywords = {Key words: Edge preserving smoothing; Image processing; Neural network architectures; Non-linear filtering; Quantitative performance measures}
}


@article{Zhukovsky2018,
  author = {Zhukovskiy, Aleksandr Evgenevich and Limonova, Elena Evgenevna and Nikolaev, Dmitry Petrovich},
  title = {Exact implementation of common image processing algorithms using fully convolutional networks},
  year = 2018,
  journal = {Trudy ISA RAN},
  editor = {Popkov Yuriy Solomonovich, akademik RAN, d.t.n., prof.},
  publisher = {Federalnoe gosudarstvennoe uchrezhdenie "Federalnyy issledovatelskiy tsentr  "Informatika i upravlenie" Rossiyskoy akademii nauk" (FITs IU RAN).},
  address = {119312, г. Москва, проспект 60-летия Октября, д.9, к.501},
  organization = {FRC CSC RAS},
  volume = 68,
  number = {Special issue S1},
  pages = {108--116},
  institution = {FRC CSC RAS},
  note={DOI: 10.14357/20790279180512}
}

%%%%%%%%%%% 1.2 PARAMETERIZATION %%%%%%%%%%% 

%%%%%%%%%%% 1.2.1 Relevance of parameterization %%%%%%%%%%% 


@Article{CannyCloudDetection,
AUTHOR = {Lapušinskij, Aleksandr and Suzdalev, Ivan and Goranin, Nikolaj and Janulevičius, Justinas and Ramanauskaitė, Simona and Stankūnavičius, Gintautas},
TITLE = {The Application of Hough Transform and Canny Edge Detector Methods for the Visual Detection of Cumuliform Clouds},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {17},
ARTICLE-NUMBER = {5821},
URL = {https://www.mdpi.com/1424-8220/21/17/5821},
PubMedID = {34502711},
ISSN = {1424-8220},
ABSTRACT = {The increase in flying time of unmanned aerial vehicles (UAV) is a relevant and difficult task for UAV designers. It is especially important in such tasks as monitoring, mapping, or signal retranslation. While the majority of research is concentrated on increasing the battery capacity, it is also important to utilize natural renewable energy sources, such as solar energy, thermals, etc. This article proposed a method for the automatic recognition of cumuliform clouds. Practical application of this method allows diverting of an unmanned aerial vehicle towards the identified cumuliform cloud and improving its probability of flying into a thermal flow, thus increasing the flight time of the UAV, as is performed by glider and paraglider pilots. The proposed method is based on the application of Hough transform and Canny edge detector methods, which have not been used for such a task before. For testing the proposed method a dataset of different clouds was generated and marked by experts.},
DOI = {10.3390/s21175821}
}


@article{Precompensation,
author = {Xunbo Yu and Hanyu Li and Xinzhu Sang and Xiwen Su and Xin Gao and Boyang Liu and Duo Chen and Yuedi Wang and Binbin Yan},
journal = {Opt. Express},
keywords = {Holographic displays; Image processing; Image quality; Lens arrays; Neural networks; Optical systems},
number = {7},
pages = {11009--11020},
publisher = {OSA},
title = {Aberration correction based on a pre-correction convolutional neural network for light-field displays},
volume = {29},
month = {Mar},
year = {2021},
url = {http://opg.optica.org/oe/abstract.cfm?URI=oe-29-7-11009},
doi = {10.1364/OE.419570},
abstract = {Lens aberrations degrade the image quality and limit the viewing angle of light-field displays. In the present study, an approach to aberration reduction based on a pre-correction convolutional neural network (CNN) is demonstrated. The pre-correction CNN is employed to transform the elemental image array (EIA) generated by a virtual camera array into a pre-corrected EIA (PEIA). The pre-correction CNN is built and trained based on the aberrations of the lens array. The resulting PEIA, rather than the EIA, is presented on the liquid crystal display. Via the optical transformation of the lens array, higher quality 3D images are obtained. The validity of the proposed method is confirmed through simulations and optical experiments. A 70-degree viewing angle light field display with the improved image quality is demonstrated.},
}
%%%%%%%%%%% 1.2.2 Approaches to parameterization %%%%%%%%%%% 

@misc{CondConv2020,
      title={CondConv: Conditionally Parameterized Convolutions for Efficient Inference}, 
      author={Brandon Yang and Gabriel Bender and Quoc V. Le and Jiquan Ngiam},
      year={2020},
      eprint={1904.04971},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@InProceedings{DynamicConv2020,
author = {Chen, Yinpeng and Dai, Xiyang and Liu, Mengchen and Chen, Dongdong and Yuan, Lu and Liu, Zicheng},
title = {Dynamic Convolution: Attention Over Convolution Kernels},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}


@Article{MultipleInputNN_Water2020,
AUTHOR = {Wei, Chih-Chiang},
TITLE = {Comparison of River Basin Water Level Forecasting Methods: Sequential Neural Networks and Multiple-Input Functional Neural Networks},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {4172},
URL = {https://www.mdpi.com/2072-4292/12/24/4172},
ISSN = {2072-4292},
ABSTRACT = {To precisely forecast downstream water levels in catchment areas during typhoons, the deep learning artificial neural networks were employed to establish two water level forecasting models using sequential neural networks (SNNs) and multiple-input functional neural networks (MIFNNs). SNNs, which have a typical neural network structure, are network models constructed using sequential methods. To develop a network model capable of flexibly consolidating data, MIFNNs are employed for processing data from multiple sources or with multiple dimensions. Specifically, when images (e.g., radar reflectivity images) are used as input attributes, feature extraction is required to provide effective feature maps for model training. Therefore, convolutional layers and pooling layers were adopted to extract features. Long short-term memory (LSTM) layers adopted during model training enabled memory cell units to automatically determine the memory length, providing more useful information. The Hsintien River basin in northern Taiwan was selected as the research area and collected relevant data from 2011 to 2019. The input attributes comprised one-dimensional data (e.g., water levels at river stations, rain rates at rain gauges, and reservoir release) and two-dimensional data (i.e., radar reflectivity mosaics). Typhoons Saola, Soudelor, Dujuan, and Megi were selected, and the water levels 1 to 6 h after the typhoons struck were forecasted. The results indicated that compared with linear regressions (REG), SNN using dense layers (SNN-Dense), and SNN using LSTM layers (SNN-LSTM) models, superior forecasting results were achieved for the MIFNN model. Thus, the MIFNN model, as the optimal model for water level forecasting, was identified.},
DOI = {10.3390/rs12244172}
}


@inproceedings{AdjustableUnet,
author = {Jingyi Song and Zhiqiang Tian and Chengyang Zhang and Yaoyue Zheng and Xiaofu Yu and Zhong Shi},
title = {{Higher accuracy and lower complexity: convolutional neural network for multi-organ segmentation}},
volume = {11574},
booktitle = {International Symposium on Artificial Intelligence and Robotics 2020},
editor = {Huimin Lu and Jože Guna and Yujie Li},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {54 -- 59},
abstract = {In computed tomography (CT), segmentation of organs-at-risk (OARs) is a key task in formulating the radiation therapy (RT) plan. However, it takes a lot of time to delineate OARs slice by slice in CT scans. The proposal of deep convolutional neural networks makes it possible to effectively segment medical images automatically. In this work, we propose an improved 2D U-Net to segment multiple OARs, aiming to increase accuracy while reducing complexity. Our method replaces vanilla convolutions with Octave Convolution (OctConv) units to reduce memory use and computation cost without accuracy sacrifice. We further plug a ‘Selective Kernel’ (SK) block after the encoder to capture multi-scale information and adaptively recalibrate the learned feature maps with attention mechanism. An in-house dataset is used to evaluate our method, where four chest organs are involved: left lung, right lung, heart, and spinal cord. 
keywords = {convolutional neural network, organs at risk, multi-scale, CT segmentation, multi-organ},
year = {2020},
doi = {10.1117/12.2577009},
URL = {https://doi.org/10.1117/12.2577009}
}



@Article{MultipleInputNN_SoilClay2020,
AUTHOR = {Tziolas, Nikolaos and Tsakiridis, Nikolaos and Ben-Dor, Eyal and Theocharis, John and Zalidis, George},
TITLE = {Employing a Multi-Input Deep Convolutional Neural Network to Derive Soil Clay Content from a Synergy of Multi-Temporal Optical and Radar Imagery Data},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {1389},
URL = {https://www.mdpi.com/2072-4292/12/9/1389},
ISSN = {2072-4292},
ABSTRACT = {Earth observation (EO) has an immense potential as being an enabling tool for mapping spatial characteristics of the topsoil layer. Recently, deep learning based algorithms and cloud computing infrastructure have become available with a great potential to revolutionize the processing of EO data. This paper aims to present a novel EO-based soil monitoring approach leveraging open-access Copernicus Sentinel data and Google Earth Engine platform. Building on key results from existing data mining approaches to extract bare soil reflectance values the current study delivers valuable insights on the synergistic use of open access optical and radar images. The proposed framework is driven by the need to eliminate the influence of ambient factors and evaluate the efficiency of a convolutional neural network (CNN) to effectively combine the complimentary information contained in the pool of both optical and radar spectral information and those form auxiliary geographical coordinates mainly for soil. We developed and calibrated our multi-input CNN model based on soil samples of the LUCAS database and then applied this approach to predict soil clay content.},
DOI = {10.3390/rs12091389}
}


@misc{GCN2021covid19,
      title={Covid-19 Detection from Chest X-ray and Patient Metadata using Graph Convolutional Neural Networks}, 
      author={Thosini Bamunu Mudiyanselage and Nipuna Senanayake and Chunyan Ji and Yi Pan and Yanqing Zhang},
      year={2021},
      eprint={2105.09720},
      archivePrefix={arXiv},
      primaryClass={eess.IV}
}



@article{Plankton2019,
author = {Ellen, Jeffrey S. and Graff, Casey A. and Ohman, Mark D.},
title = {Improving plankton image classification using context metadata},
journal = {Limnology and Oceanography: Methods},
volume = {17},
number = {8},
pages = {439-461},
doi = {https://doi.org/10.1002/lom3.10324},
url = {https://aslopubs.onlinelibrary.wiley.com/doi/abs/10.1002/lom3.10324},
eprint = {https://aslopubs.onlinelibrary.wiley.com/doi/pdf/10.1002/lom3.10324},
abstract = {Abstract Advances in both hardware and software are enabling rapid proliferation of in situ plankton imaging methods, requiring more effective machine learning approaches to image classification. Deep Learning methods, such as convolutional neural networks (CNNs), show marked improvement over traditional feature-based supervised machine learning algorithms, but require careful optimization of hyperparameters and adequate training sets. Here, we document some best practices in applying CNNs to zooplankton and marine snow images and note where our results differ from contemporary Deep Learning findings in other domains. We boost the performance of CNN classifiers by incorporating metadata of different types and illustrate how to assimilate metadata beyond simple concatenation. We utilize both geotemporal (e.g., sample depth, location, time of day) and hydrographic (e.g., temperature, salinity, chlorophyll a) metadata and show that either type by itself, or both combined, can substantially reduce error rates. Incorporation of context metadata also boosts performance of the feature-based classifiers we evaluated: Random Forest, Extremely Randomized Trees, Gradient Boosted Classifier, Support Vector Machines, and Multilayer Perceptron. For our assessments, we use an original data set of 350,000 in situ images (roughly 50\% marine snow and 50\% non-snow sorted into 26 categories) from a novel in situ Zooglider. We document asymptotically increasing performance with more computationally intensive techniques, such as substantially deeper networks and artificially augmented data sets. Our best model achieves 92.3\% accuracy with our 27-class data set. We provide guidance for further refinements that are likely to provide additional gains in classifier accuracy.},
year = {2019}
}


@article{EfficientNetMetaData2020,
title = {Skin lesion classification using ensembles of multi-resolution EfficientNets with meta data},
journal = {MethodsX},
volume = {7},
pages = {100864},
year = {2020},
issn = {2215-0161},
doi = {https://doi.org/10.1016/j.mex.2020.100864},
url = {https://www.sciencedirect.com/science/article/pii/S2215016120300832},
author = {Nils Gessert and Maximilian Nielsen and Mohsin Shaikh and René Werner and Alexander Schlaefer},
keywords = {Deep Learning, Multi-class skin lesion classification, Convolutional neural networks},
abstract = {In this paper, we describe our method for the ISIC 2019 Skin Lesion Classification Challenge. The challenge comes with two tasks. For task 1, skin lesions have to be classified based on dermoscopic images. For task 2, dermoscopic images and additional patient meta data are used. Our deep learning-based method achieved first place for both tasks. The are several problems we address with our method. First, there is an unknown class in the test set which we cover with a data-driven approach. Second, there is a severe class imbalance that we address with loss balancing. Third, there are images with different resolutions which motivates two different cropping strategies and multi-crop evaluation. Last, there is patient meta data available which we incorporate with a dense neural network branch. • We address skin lesion classification with an ensemble of deep learning models including EfficientNets, SENet, and ResNeXt WSL, selected by a search strategy. • We rely on multiple model input resolutions and employ two cropping strategies for training. We counter severe class imbalance with a loss balancing approach. • We predict an additional, unknown class with a data-driven approach and we make use of patient meta data with an additional input branch.}
}


@inproceedings{AdaptiveConvolutions2017,
 author = {Kang, Di and Dhar, Debarun and Chan, Antoni},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Incorporating Side Information by Adaptive Convolution},
 url = {https://proceedings.neurips.cc/paper/2017/file/e7e23670481ac78b3c4122a99ba60573-Paper.pdf},
 volume = {30},
 year = {2017}
}


%%%%%%%%%%% 1.3 Relevance of the study %%%%%%%%%%% 

@article{Jampani2016LearningSH,
  title={Learning Sparse High Dimensional Filters: Image Filtering, Dense CRFs and Bilateral Neural Networks},
  author={V. Jampani and Martin Kiefel and Peter V. Gehler},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={4452-4461}
}


@InProceedings{Yi2016LearnedIFT,
author="Yi, Kwang Moo
and Trulls, Eduard
and Lepetit, Vincent
and Fua, Pascal",
editor="Leibe, Bastian
and Matas, Jiri
and Sebe, Nicu
and Welling, Max",
title="LIFT: Learned Invariant Feature Transform",
booktitle="Computer Vision -- ECCV 2016",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="467--483",
abstract="We introduce a novel Deep Network architecture that implements the full feature point handling pipeline, that is, detection, orientation estimation, and feature description. While previous works have successfully tackled each one of these problems individually, we show how to learn to do all three in a unified manner while preserving end-to-end differentiability. We then demonstrate that our Deep pipeline outperforms state-of-the-art methods on a number of benchmark datasets, without the need of retraining.",
isbn="978-3-319-46466-4"
}


@INPROCEEDINGS{Febbo2018KCNN,
  author={Di Febbo, Paolo and Dal Mutto, Carlo and Tieu, Kinh and Mattoccia, Stefano},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={KCNN: Extremely-Efficient Hardware Keypoint Detection with a Compact Convolutional Neural Network}, 
  year={2018},
  volume={},
  number={},
  pages={795-7958},
  doi={10.1109/CVPRW.2018.00111}}
  

%%%%%%%%%%%%%%%%%%%%%%%%%%%% 2 EVALUATION %%%%%%%%%%%%%%%%%%%%%%%%%%%% 

@ARTICLE{CannyPaper,
  author={Canny, John},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={A Computational Approach to Edge Detection}, 
  year={1986},
  volume={PAMI-8},
  number={6},
  pages={679-698},
  doi={10.1109/TPAMI.1986.4767851}}

@ARTICLE{CNNSurvey,
  author={Li, Zewen and Liu, Fan and Yang, Wenjie and Peng, Shouheng and Zhou, Jun},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={A Survey of Convolutional Neural Networks: Analysis, Applications, and Prospects}, 
  year={2021},
  volume={},
  number={},
  pages={1-21},
  doi={10.1109/TNNLS.2021.3084827}}
  
  
@article{LHS,
author = {Mckay, M. and Beckman, Richard and Conover, William},
year = {1979},
month = {05},
pages = {239-245},
title = {A Comparison of Three Methods for Selecting Vales of Input Variables in the Analysis of Output From a Computer Code},
volume = {21},
journal = {Technometrics},
doi = {10.1080/00401706.1979.10489755}
}



@Article{TubeCountour,
AUTHOR = {Cheng, Xiaoqi and Sun, Junhua and Zhou, Fuqiang},
TITLE = {A Fully Convolutional Network-Based Tube Contour Detection Method Using Multi-Exposure Images},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {4095},
URL = {https://www.mdpi.com/1424-8220/21/12/4095},
PubMedID = {34198632},
ISSN = {1424-8220},
ABSTRACT = {The tube contours in two-dimensional images are important cues for optical three-dimensional reconstruction. Aiming at the practical problems encountered in the application of tube contour detection under complex background, a fully convolutional network (FCN)-based tube contour detection method is proposed. Multi-exposure (ME) images are captured as the input of FCN in order to get information of tube contours in different dynamic ranges, and the U-Net type architecture is adopted by the FCN to achieve pixel-level dense classification. In addition, we propose a new loss function that can help eliminate the adverse effects caused by the positional deviation and jagged morphology of tube contour labels. Finally, we introduce a new dataset called multi-exposure tube contour dataset (METCD) and a new evaluation metric called dilate inaccuracy at optimal dataset scale (DIA-ODS) to reach an overall evaluation of our proposed method. The experimental results show that the proposed method can effectively improve the integrity and accuracy of tube contour detection in complex scenes.},
DOI = {10.3390/s21124095}
}

@article{EdgeDetectionIOU,
author = {Zheng, Zhen and Zha, Bingting and Xuchen, Youshi and Yuan, Hailu and Gao, Yanliang and Zhang, He},
year = {2019},
month = {07},
pages = {1-1},
title = {Adaptive Edge Detection Algorithm Based on Grey Entropy Theory and Textural Features},
volume = {PP},
journal = {IEEE Access},
doi = {10.1109/ACCESS.2019.2927655}
}

@article{limonova2020fast,
  title={Fast implementation of morphological filtering using {ARM} {NEON} extension},
  author={Limonova, Elena and Terekhin, Arseny and Nikolaev, Dmitry and Arlazarov, Vladimir},
  journal={arXiv preprint arXiv:2002.09474},
  year={2020}
}

% implementation in the industrial recognition systems

@inproceedings{panfilova2021fast,
  author = {Panfilova, Ekaterina I. and Shipitko, Oleg S. and Kunina, Irina A.},
  title = {Fast Hough Transform-Based Road Markings Detection For Autonomous Vehicle},
  year = 2021,
  booktitle = {ICMV 2020},
  publisher = {Society of Photo-Optical Instrumentation Engineers (SPIE)},
  address = {Bellingham, Washington 98227-0010 USA},
  volume = 11605,
  month = {Jan.},
  number = {116052B},
  note={DOI: 10.1117/12.2587615}
}

@article{panfilova2020using,
  author = {Panfilova, E. I. and Kunina, I. A.},
  title = {Using window hough transform for detecting elongated boundaries in an image},
  year = 2020,
  journal = {Sensory systems},
  editor = {Mikhail Arkadevich. Ostrovskiy, akademik RAN, d.b.n.},
  publisher = {OOO "IKTs "Akademkniga""},
  address = {117485, Москва, Профсоюзная улица, дом 90},
  volume = 34,
  number = {4},
  pages = {340--353},
  note={DOI: 10.31857/S0235009220030075}
}


@article{erlygin2021improvement,
  author = {Erlygin, L. A. and Teplyakov, L. M.},
  title = {Improvement of a line segment detector based on a neural network by adding engineering features},
  year = 2021,
  journal = {Sensory systems},
  editor = {Mikhail Arkadevich. Ostrovskiy, akademik RAN, d.b.n.},
  publisher = {OOO "IKTs "Akademkniga""},
  address = {117485, Москва, Профсоюзная улица, дом 90},
  volume = 35,
  number = {1},
  pages = {50--54},
  note={DOI: 10.31857/S0235009221010042}
}

