\chapter{Обзор литературы}
\label{cha:Obzor}

Изучение аппроксимирующей способности искусственных нейронных сетей началось еще во второй половине XX в. Так, в 1969 г. M. Minsky и S. Papert показали \cite{MinskyPapert69}, что при помощи элементарного персептрона с одним скрытым слоем с заданной степенью точности возможно аппроксимировать только функции, принадлежащие достаточно узкому классу, хотя вопрос о разрешимости этой задачи для функций из более широкого класса при помощи многослойного персептрона остался открытым. В дальнейшем было доказано, что двухслойная полносвязная сеть позволяет достичь хорошего качества аппроксимации функции любого класса, если функция активации на выходном слое является монотонной \cite{LeCun1987}, \cite{LapedesFarber1987}. Аналогичный результат был получен для нейронной сети с одним слоем \cite{IrieMiyake88}, однако работа имела лишь теоретическую значимость в силу того, что число нейронов скрытого слоя в таком случае должно быть бесконечным. Наконец, в работе K. Hornik, M. Stinchcombe и H. White \cite{Hornik89} было предоставлено строгое доказательство того, что двуслойный персептрон с произвольной выходной функцией активации способен аппроксимировать любую измеримую по Борелю функцию, заданную на конечномерном пространстве, с заданной степенью точности – необходимо лишь задать подходящее количество нейронов в скрытом слое. Таким образом, нейронные сети прямого распространения представляют собой класс универсальных аппроксиматоров.

Приведенный выше обзор относится к полносвязной модели нейронной сети, однако попытки исследовать аппроксимирующую способность сверточных нейронных сетей также предпринимались. Теоретические исследования были проведены D. Zhou \cite{Zhou20}, который доказал аналог универсальной теоремы аппроксимации для глубоких сверточных сетей: сверточные нейронные сети могут аппроксимировать любую непрерывную функцию с заданной степенью точности при достаточном числе скрытых слоев. Кроме того, глубокие сверточные сети являются более эффективным решением с точки зрения числа обучаемых параметров в случае большой размерности данных. В работе \cite{Petersen2018EquivalenceOA} было установлено соответствие между нейронной сетью прямого распространения и сверточной нейронной сетью, не использующей операции пуллинга или паддинга. Выводом работы является доказательство того, что верхние и нижние оценки скорости аппроксимации функции из произвольного класса персептроном и сверточной нейронной сетью при выполнении определенных условий совпадают.

Стоит отметить, что в рассмотренных работах исследуется способность нейронных сетей получать хорошие приближения аналитически заданных функций. Однако вопрос о возможности аппроксимации при помощи нейронной сети алгоритмов – в частности, алгоритмов обработки изображений, – остается открытым. Целью настоящей работы является исследование эффективности аппроксимации классических алгоритмов обработки и улучшения изображения нейросетевыми моделями при использовании архитектур нейронных сетей общего назначения. Мы хотим проверить гипотезу о том, что модель искусственной нейронной сети является универсальным аппроксиматором для широкого класса задач, в частности – может аппроксимировать работу классических алгоритмов фильтрации изображений, применяемых в распознающих индустриальных системах. 

При решении практических задач применение классических фильтров для обработки изображений все еще весьма распространенно, однако разработка нейросетевых моделей, аппроксимирующих классические алгоритмы, ведется в научном сообществе достаточно активно. Актуальность таких исследований заключается в том, что модель нейронной сети является обучаемой, а значит, потенциально может достигать лучшего качества, чем классический детерминированный алгоритм. Например, в работе \cite{Jampani2016LearningSH} предлагается алгоритм на основе градиентного спуска для оптимизации параметров билатерального фильтра в процессе обучения. Этот алгоритм позволяет встроить обучаемое билатеральное ядро в архитектуру нейронной сети, в результате чего был предложен новый тип слоя нейронной сети – билатеральный сверточный слой. В ходе экспериментов модель с обучаемым билатеральным ядром достигла лучшего качества, чем модель с фиксированными параметрами ядра. Исследование позволяет предположить, что использование обучаемого ядра потенциально может улучшить работу как нейросетевых, так и классических алгоритмов, использующих этот фильтр, и этот вывод может быть корректен не только по отношению к билатеральному фильтру.

К практическим преимуществам использования нейросетевой модели вместо классического алгоритма обработки изображений можно также отнести:

- возможность встраивания нейросетевой аппроксимации алгоритма в более сложную модель, что позволяет построить end-to-end модель \cite{Yi2016LearnedIFT}, которую проще проектировать и обучать;

- возможность реализации нейросетевой модели на графических процессорах, развитие которых приводит к уменьшению времени обучения и инференса модели, а также энергопотребления \cite{Febbo2018KCNN}.

Интерес к теме исследования является довольно давним: первые практические попытки построения нейросетевой модели фильтров изображений были предприняты еще в XX в. Например, работа \cite{Ridder99Kuwahara} посвящена исследованию возможности применения нейронных сетей к нелинейной обработке изображений на примере фильтра Kuwahara, предназначенного для сглаживания изображений. Авторы провели эксперименты с несколькими архитектурами, включающими в себя однослойный и двуслойный персептроны с различным числом нейронов в скрытом слое и специальным образом разработанную модульную нейронную сеть прямого распространения. Несмотря на то что авторам удалось обучить модель сглаживать изображения, результат все еще был далек от истинного сглаживания фильтром Kuwahara, что могло произойти вследствие неподходящей архитектуры моделей и функции потерь. 

В работе \cite{Fernandez11} аналогичные попытки предпринимаются для построения нейросетевой аппроксимации детекторов краев Canny и Sobel. Также была использована модель однослойного персептрона, однако для учета пространственной зависимости на изображениях, на вход модели подавалось не все изображение, а пиксель и 8 его соседних пикселя, что практически соответствует сверточному слою с размером ядра 3×3. Как и в работе \cite{Ridder99Kuwahara}, достичь хорошего качества аппроксимации выбранных детекторов углов не удалось, что, возможно, может быть объяснено неспособностью однослойной модели выучивать сложные зависимости в данных. Однако эти исследования могут быть взяты в качестве начальной основы для последующих экспериментов

Аппроксимация работы алгоритмов может быть осуществлена двумя способами. Первый способ – и наиболее распространенный – это обучение модели нейронной сети на датасете, который может быть либо получен применением соответствующего фильтра к исходным изображениям. Архитектура модели задается исследователем. В некоторых работах – например, \cite{Wibisono2020TraditionalMI}, она базируется на внутреннем устройстве аппроксимируемого алгоритма. Основываясь на традиционных алгоритмах выделения контуров, исследователи предложили нейросетевую модель, состоящую из трех частей. Первая часть, обеспечивающая извлечение признаков (feature extraction), аппроксимирует работу дифференциальных операторов. Вторая часть – получение дополнительной информации (enrichment), аппроксимирует фильтры нижних частот. Третья часть – обобщение (summarization), производит окончательный вывод модели.

Во многих работах для решения задачи обработки и фильтрации изображений прибегают к конструированию нейронных сетей достаточно сложной архитектуры, требующих нетривиальных подходов к обучению. Так, например, одним из последних state-of-the-art решений для детекции контуров, представленным в 2020 г. в работе \cite{Soria2020DenseEI}, является сверточная нейронная сеть Dexined, состоящая из двух подсетей: энкодер с архитектурой xception и up-sampling блока. Модель Dexined не использует предобученные веса и может быть обучена с нуля за одну эпоху. Другим примером являются нейронные сети, решающие задачи повышения разрешения изображения (superresolution). На текущий момент наилучшее качество на различных бенчмарках демонстрирует модель HAN \cite{Niu2020SingleIS}, состоящая из четырех частей: блок выделения признаков, два модуля внимания и блок реконструкции. Для бинаризации изображений, в частности – фотографий документов, была разработана каскадная нейронная сеть архитектуры энкодер-декодер \cite{Sheng2021CTNet}.

Однако state-of-the-art модели зачастую содержат достаточно большое количество параметров, из-за чего для их обучения требуется большой тренировочный датасет и значительные вычислительные мощности. Кроме того, обученная модель является достаточно тяжеловесной и не всегда может быть встроена в системы, предъявляющие высокие требования к занимаемой моделью памяти и временем инференса. В целом, архитектура модели может быть весьма общей, и даже простые модели с небольшим числом параметром \cite{Ridder99Kuwahara}, \cite{Fernandez11}, \cite{Febbo2018KCNN} могут демонстрировать неплохое качество, которое, однако, можно улучшить.

Второй способ – это полное воспроизведение исходного алгоритма при помощи операций, используемых в нейронных сетях: сверток, пулингов, конкатенации и др. Например, представление детектора краев Кэнни, детектора углов Харриса и бинаризации Ниблэка в виде искусственных нейронных сетей проведено в работе А. Жуковского, Е. Лимоновой и Д. Николаева \cite{Zhukovsky2018}. Благодаря тому, что внутреннее устройство алгоритмов позволяет реализовать их в терминах нейронных сетей, инициализацию параметров оригинальных алгоритмов не нужно проводить вручную или с привлечением специально разработанных методов – на основе алгоритма обратного распространения ошибки оптимальные значения параметров будут определены в ходе обучения. Единственным параметром, который потребуется подобрать, является размер рецептивного поля оператора. Кроме того, обучение модели позволяет не только оптимизировать параметры алгоритма, но и модифицировать используемые в нем фильтры, а также использовать современные техники машинного обучения (dropout, batch normalization, регуляризация), которые потенциально могут улучшить качество модели.

Поскольку целью нашего исследования является проверка гипотезы, что глубокие нейронные сети являются универсальным аппроксиматором для широкого класса задач, мы будем придерживаться первого подхода. Однако при аппроксимации различных алгоритмов обработки изображений мы не будем разрабатывать архитектуру для каждого алгоритма в отдельности, а будем использовать модели с общей универсальной архитектурой.

